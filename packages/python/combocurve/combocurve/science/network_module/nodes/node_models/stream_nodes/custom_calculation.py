import numpy as np
from functools import partial

from combocurve.shared.date import date_obj_from_npdatetime64
from combocurve.science.network_module.nodes.node_models.stream_nodes.stream_shared_node import StreamSharedNode
from combocurve.science.network_module.nodes.shared.helper import (get_db_node_id, apply_time_series_allocation,
                                                                   sum_stream_date_and_value_for_more,
                                                                   sum_stream_date_and_value_for_2)
from combocurve.science.network_module.nodes.shared.type_hints import (Edge, EdgeDataMap, StreamDateAndValue,
                                                                       Float_Or_StreamDateAndValue,
                                                                       MonthlyFrequencyDatetime64mNDArray, Int32NDArray)
from combocurve.science.network_module.nodes.shared.fluid_model_manager import fluid_model_manager

from combocurve.science.network_module.parser.lexer import Lexer
from combocurve.science.network_module.parser.parser import Parser
from combocurve.science.network_module.parser.nodes import AllNodesTyping


def calculate_fpd(well_info, value):
    return {'date': np.array([well_info['date_dict']['first_production_date']]), 'value': np.array([value])}


def _map_product(custom_product):
    return custom_product if custom_product != 'CH4' else 'C1'


def calculate_custom_calculation_as_facility_node(node_data, well_count_arr: Int32NDArray,
                                                  date: MonthlyFrequencyDatetime64mNDArray) -> dict:
    """Calculates emissions from pneumatic device node.

    Arguments:
        node_data: params stored in a node, {'fluid_model': {}, 'time_series': {'criteria': str, 'rows': []}}
        well_count_arr: number of active wells at each time_stamp for this facility
        date: an array of date that is the same length as well_count_arr
    Returns:
        A dictionary of time series of per well emission from overall_min_date to overall_max_date, plus the category
        and emission type
    """
    custom_node = CustomCalculation(node_data['id'], node_data['params'])
    outputs = custom_node.calculate_outputs_as_facility_node(date)
    ret = {}
    for output_key, output_data in outputs.items():
        if output_key in ['CO2', 'CH4', 'N2O', 'CO2e']:
            product_date = output_data['date']
            product_value = output_data['value']

            product_date_index = [(np.datetime64(date_obj.strftime('%Y-%m-%d'), 'M') - date[0]).astype(int)
                                  for date_obj in product_date]

            product = _map_product(output_key)

            output_setting = custom_node.outputs_map[output_key]
            emission_category = output_setting['category']
            emission_type = output_setting['emission_type']

            ret_value = np.zeros_like(well_count_arr)
            ret_value[product_date_index] = product_value
            valid_well_count_arr_mask = well_count_arr > 0
            ret_value[~valid_well_count_arr_mask] = 0
            ret_value[valid_well_count_arr_mask] = ret_value[valid_well_count_arr_mask] / well_count_arr[
                valid_well_count_arr_mask]

            ret[product] = {'emission_category': emission_category, 'emission_type': emission_type, 'value': ret_value}

    return ret


class CustomCalculation(StreamSharedNode):
    node_type = 'custom_calculation'

    def __init__(self, node_id, params):
        '''
        This node inherits self.storage from StreamSharedNode

        Also it will have self.self_emission for itself, these 2 storages have different keys

        self.storage is used when other nodes generate emission and want to assign emission to this custom_calculation

        self.self_storage is used to track emission generated by this custom_calculation node
        '''
        super().__init__(node_id, params)
        self.self_emission = {}

        self.fluid_model_id = fluid_model_manager.get_fluid_model_id(self.params.get('fluid_model'))

        ##
        self.inputs_map = {input_['name']: input_ for input_ in self.params['inputs']}

        self.outputs_map = {output_['name']: output_ for output_ in self.params['outputs']}

        self.formula_map = {formula['output']: formula['formula'] for formula in self.params['formula']['simple']}

        self.formula_ast = self._parse_output_formula()

    def _parse_output_formula(self) -> dict[str, AllNodesTyping]:
        ## get ast for all formula output
        formula_ast: dict[str, AllNodesTyping] = {}
        for output_key, formula_str in self.formula_map.items():
            tokens = Lexer(formula_str).generate_tokens()
            ast = Parser(tokens).parse()
            formula_ast[output_key] = ast

        return formula_ast

    def _get_total_inputs(self, input_edges, edge_data_map) -> dict[str, StreamDateAndValue]:
        to_be_added_stream: dict[str, list[StreamDateAndValue]] = {input_name: [] for input_name in self.inputs_map}

        for input_edge in input_edges:
            input_edge_id = input_edge['id']
            input_edge_data = edge_data_map.get(input_edge_id)
            if input_edge_data is None:
                continue

            input_edge_port_name = input_edge['toHandle']

            to_be_added_stream[input_edge_port_name] += [v for v in input_edge_data.values()]

        return {
            input_name: sum_stream_date_and_value_for_more(input_streams)
            for input_name, input_streams in to_be_added_stream.items() if len(input_streams) > 0
        }

    def _calculate_outputs(self, total_inputs, well_info) -> dict[str, StreamDateAndValue]:
        ret: dict[str, StreamDateAndValue] = {}
        functions = {'@FPD': partial(calculate_fpd, well_info=well_info)}

        for output_name, output_formula_ast in self.formula_ast.items():
            ret[output_name] = _eval_ast(output_formula_ast, total_inputs, functions, well_info)

        return ret

    def calculate_outputs_as_facility_node(
            self, date_arr: MonthlyFrequencyDatetime64mNDArray) -> dict[str, StreamDateAndValue]:
        ## HACK: this relies on the frontend do not have @FPD used
        ## TODO: check this date_arr matches the required data type

        return self._calculate_outputs(
            {}, {'well_data': {
                'date': np.array(list(map(date_obj_from_npdatetime64, date_arr)))
            }})

    def calculate_output_edges_and_emission(self, input_edges: list[Edge], output_edges: list[Edge],
                                            edge_data_map: EdgeDataMap, network_nodes_map: dict,
                                            well_info: dict) -> EdgeDataMap:
        total_inputs = self._get_total_inputs(input_edges, edge_data_map)

        ## calculate outputs
        outputs = self._calculate_outputs(total_inputs, well_info)

        ## apply edge params and get output_edge_data
        output_edge_data: EdgeDataMap = {}
        for output_edge in output_edges:
            output_edge_id = output_edge['id']
            output_edge_port = output_edge['fromHandle']
            output_data = outputs[output_edge_port]
            output_edge_data[output_edge_id] = {
                self.fluid_model_id: {
                    'value':
                    apply_time_series_allocation(output_data['date'], output_data['value'], output_edge['params'],
                                                 well_info['date_dict']),
                    'date':
                    output_data['date']
                }
            }

        ## calculate emission generated in this node
        well_id_str = well_info['well_id']
        for output_key, output_data in outputs.items():
            if output_key in ['CO2', 'CH4', 'N2O', 'CO2e']:
                output_setting = self.outputs_map[output_key]
                emission_category = output_setting['category']
                emission_type = output_setting['emission_type']
                storage_key = self._get_self_emission_key(well_id_str, emission_category, emission_type, output_key)
                self._add_to_self_emission(storage_key, output_data)

        return output_edge_data

    def _get_self_emission_key(self, well_id, emission_category, emission_type, product):
        return (well_id, emission_category, emission_type, product)

    def _add_to_self_emission(self, self_emission_key, stream_date_and_value):
        self.self_emission[self_emission_key] = sum_stream_date_and_value_for_2(
            stream_date_and_value, self.self_emission.get(self_emission_key))

    def generate_final_emission_data(self, well_data: dict, well_info: dict, facility_id: str = None) -> list:
        '''
        Get the final emission data

        Consists of 2 parts:
        1. self.storage, which is managed by SharedStreamNode's methods
        2. self.self_emission, which is managed by _get_self_emission_key, _add_to_self_emission and this method
        '''
        ## get the emission produced from outside this node
        ret = []

        for (well_id, emission_type, product_type, product, port), date_and_value in self.storage.items():
            emission_category = self.outputs_map[port]['category']
            date = date_and_value['date']
            value = date_and_value['value']
            ret += [
                {
                    'well_id': well_id,
                    'node_id': get_db_node_id(self.id, facility_id),
                    'node_type': emission_category,  ## each input can have their own emission category
                    'emission_type': emission_type,
                    'product_type': product_type,
                    'product': product,
                    'value': float(v),
                    'date': date[i]
                } for i, v in enumerate(value)
            ]

        ## get emission produced within this node
        for (well_id, emission_category, emission_type, product), date_and_value in self.self_emission.items():
            date = date_and_value['date']
            value = date_and_value['value']
            ret += [
                {
                    'well_id': well_id,
                    'node_id': get_db_node_id(self.id, facility_id),
                    'node_type': emission_category,
                    'emission_type': emission_type,
                    'product_type': 'ghg',
                    ## HACK: we should keep terminology the same across all places
                    'product': _map_product(product),
                    'value': float(v),
                    'date': date[i]
                } for i, v in enumerate(value)
            ]

        return ret


def _eval_ast(output_formula_ast, inputs, functions, well_info) -> StreamDateAndValue:
    '''
    Evaluate ast with the streams and functions

    The evaluated result can be a float, in that case we need to convert the float value to StreamDateAndValue
    '''
    raw_result: Float_Or_StreamDateAndValue = output_formula_ast.eval(inputs, functions)

    if type(raw_result) != float:
        return raw_result

    well_data = well_info['well_data']
    return {'date': well_data['date'], 'value': np.ones_like(well_data['date'], dtype=float) * raw_result}
