from datetime import date, datetime
from pandas import Timestamp, NaT, isna
import numpy as np
import pyarrow as pa
import pyarrow.parquet as pq
import io
import logging

MAX_NUMERIC_DIGIT = 9

PA_TYPE_MAP = {
    'DATE': pa.date32(),
    'DATETIME': pa.timestamp('us'),
    'NUMERIC': pa.decimal128(29, 9),
    'STRING': pa.string(),
    'TIMESTAMP': pa.timestamp('us'),
    'INTEGER': pa.int64(),
    'FLOAT': pa.float64(),
    'BOOLEAN': pa.bool_()
}

# https://stackoverflow.com/questions/59682833/
PARQUET_ARGS = {'coerce_timestamps': 'us', 'allow_truncated_timestamps': True}


def to_date(date_or_str):
    # https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types?hl=zh-tw#date_type
    if isna(date_or_str) or type(date_or_str) == type(NaT):
        return None
    if type(date_or_str) == date:
        return date_or_str
    if type(date_or_str) in [datetime, Timestamp]:
        return date_or_str.date()
    if type(date_or_str) in [np.float64, float]:
        return datetime.fromtimestamp(date_or_str).date()
    if type(date_or_str) in [str, np.str_] and '/' in date_or_str:
        [mm, dd, yyyy] = date_or_str.split('/')
        return datetime.fromisoformat(f'{yyyy}-{mm}-{dd}').date()
    if type(date_or_str) in [str, np.str_] and '-' in date_or_str:
        date_or_str = date_or_str[:10]
        return datetime.fromisoformat(date_or_str).date()
    if type(date_or_str) == np.datetime64:
        return date_or_str.astype('datetime64[s]').item().date()
    if type(date_or_str) == int:
        return datetime.fromtimestamp(date_or_str / 1e9).date()
    '''
    wrong data format (highly likely from well header data) should be added to warning message when we build
    better econ error report in future, log warning for now
    '''
    logging.error(f'Unable to parse date "{date_or_str}"')
    return None


def build_pyarrow_schema(bq_schema, df):
    fields = []
    for item, bq_type in bq_schema.items():
        if item in df.columns:
            pa_type = PA_TYPE_MAP[bq_type]
            fields.append(pa.field(item, pa_type))
    schema = pa.schema(fields)
    return schema


def df_to_parquet(df, pa_schema):
    buffer = df_to_bytes_io(df, pa_schema)
    return buffer.read()


def df_to_bytes_io(df, pa_schema):
    buffer = io.BytesIO()
    table = pa.Table.from_pandas(df, pa_schema)
    pq.write_table(table, buffer)
    buffer.seek(0)
    return buffer


def table_to_parquet(df, pa_schema):
    buffer = df_to_buffer(df, pa_schema)
    return buffer.read()


def df_to_buffer(df, pa_schema):
    # output parquet by pandas
    f = io.BytesIO()
    df.to_parquet(f, **PARQUET_ARGS)
    f.seek(0)
    # read parquet generated by pandas
    table = pq.read_table(f, schema=pa_schema)
    # ouput parquet generated by pa table
    buffer = io.BytesIO()
    pq.write_table(table, buffer)
    buffer.seek(0)
    return buffer
